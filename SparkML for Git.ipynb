{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "UWLARydQ8lQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5FDf5kv8IGR"
      },
      "outputs": [],
      "source": [
        "# Pandas is a popular data science package for Python. In this lab, we use Pandas to load a CSV file from disc to a pandas dataframe in memory.\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# pyspark is the Spark API for Python. In this lab, we use pyspark to initialize the spark context. \n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP9B454t8IGV"
      },
      "outputs": [],
      "source": [
        "# Creating a spark context class\n",
        "sc = SparkContext()\n",
        "\n",
        "# Creating a spark session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark DataFrames basic example\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qOR3H_I8IGW"
      },
      "outputs": [],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCcVr2ZV8IGX"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler, Normalizer, StandardScaler\n",
        "from pyspark.ml.stat import Correlation\n",
        "from pyspark.ml.regression import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJXF37NA8IGZ"
      },
      "outputs": [],
      "source": [
        "# Read the file using `read_csv` function in pandas\n",
        "cars = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/data/cars.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtObY0tZ8IGa"
      },
      "outputs": [],
      "source": [
        "# Preview a few records\n",
        "cars.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExE3uMEp8IGa"
      },
      "outputs": [],
      "source": [
        "cars2 = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-BD0225EN-SkillsNetwork/labs/data/cars2.csv', header=None, names=[\"mpg\", \"hp\", \"weight\"])\n",
        "cars2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qf1ut3PC8IGb"
      },
      "outputs": [],
      "source": [
        "# We use the `createDataFrame` function to load the data into a spark dataframe\n",
        "sdf = spark.createDataFrame(cars2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POwuWbFu8IGb"
      },
      "outputs": [],
      "source": [
        "# Let us look at the schema of the loaded spark dataframe\n",
        "sdf.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfEUzG2q8IGc"
      },
      "outputs": [],
      "source": [
        "# Assemble the data as vectors\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"hp\", \"weight\"],\n",
        "    outputCol=\"features\")\n",
        "\n",
        "output = assembler.transform(sdf).select('features','mpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrNlu_yL8IGd"
      },
      "outputs": [],
      "source": [
        "# Split the data\n",
        "train, test = output.randomSplit([0.75, 0.25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2yfjdgF8IGf"
      },
      "outputs": [],
      "source": [
        "# Look at features correlation\n",
        "r1 = Correlation.corr(train, \"features\").head()\n",
        "print(\"Pearson correlation matrix:\\n\" + str(r1[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzmXyNUs8IGf"
      },
      "outputs": [],
      "source": [
        "# Look at features correlation\n",
        "r2 = Correlation.corr(train, \"features\", \"spearman\").head()\n",
        "print(\"Spearman correlation matrix:\\n\" + str(r2[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Midv7ipy8IGi"
      },
      "outputs": [],
      "source": [
        "# Look at features correlation graphically\n",
        "plt.figure()\n",
        "plt.scatter(cars2[\"hp\"], cars2[\"weight\"])\n",
        "plt.xlabel(\"horsepower\")\n",
        "plt.ylabel(\"weight\")\n",
        "plt.title(\"Correlation between Horsepower and Weight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHQ5EtO78IGj"
      },
      "outputs": [],
      "source": [
        "# Normalize data\n",
        "normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_normalized\", p=1.0)\n",
        "train_norm = normalizer.transform(train)\n",
        "print(\"Normalized using L^1 norm\")\n",
        "train_norm.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIOWEGZf8IGk"
      },
      "outputs": [],
      "source": [
        "# Scaling data\n",
        "standard_scaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\n",
        "train_model = standard_scaler.fit(train)\n",
        "train_scaled = train_model.transform(train)\n",
        "train_scaled.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMHAB9ge8IGk"
      },
      "outputs": [],
      "source": [
        "test_scaled = train_model.transform(test)\n",
        "test_scaled.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnHSFoSp8IGl"
      },
      "outputs": [],
      "source": [
        "# Create a LR model\n",
        "lr = LinearRegression(featuresCol='features_scaled', labelCol='mpg', maxIter=100)\n",
        "\n",
        "# Fit the model\n",
        "lrModel = lr.fit(train_scaled)\n",
        "\n",
        "# Print the coefficients and intercept for linear regression\n",
        "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
        "print(\"Intercept: %s\" % str(lrModel.intercept))\n",
        "\n",
        "# Summarize the model over the training set and print out some metrics\n",
        "trainingSummary = lrModel.summary\n",
        "#trainingSummary.residuals.show()\n",
        "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
        "print(\"R-squared: %f\" % trainingSummary.r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0WWDYEf8IGm"
      },
      "outputs": [],
      "source": [
        "# Predict new data\n",
        "lrModel.transform(test_scaled).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OszCraiY8IG0"
      },
      "source": [
        "Copyright Â© 2021 IBM Corporation. All rights reserved.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "name": "SparkML.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "u5jGY8iX8IGV",
        "BQFXcrAG8IGW"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}